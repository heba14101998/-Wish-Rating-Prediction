{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IR-in-Arabic_Lab4-RankedRetrieval.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heba14101998/-Wish-Rating-Prediction/blob/main/Summer2021/labs/day4/IR_in_Arabic_Lab4_RankedRetrieval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZzUxXUVMVVU"
      },
      "source": [
        "\n",
        "\n",
        "# **IR in Arabic** - Summer 2021 lab day4\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kjTczIiMctt"
      },
      "source": [
        "This is one of a series of Colab notebooks created for the **IR in Arabic** course. It demonstrates how can we perform ranked retrieval and evaluate the output.\n",
        "\n",
        "The **learning outcomes** of this notebook are:\n",
        "\n",
        "\n",
        "*   Retrieval using a vector space model and a BM25 model.\n",
        "*   Evaluating the results.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkS6LLkX6HHV"
      },
      "source": [
        "### **Setup**\n",
        "We will first install Pyterrier as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6sKgPMd_-gU",
        "outputId": "acad711f-36e9-46c4-c34d-1aff6d1bdcf1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#install the Pyterrier framework\n",
        "!pip install python-terrier -q"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-terrier\n",
            "  Downloading python_terrier-0.13.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from python-terrier) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from python-terrier) (2.2.2)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from python-terrier) (10.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from python-terrier) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from python-terrier) (2.32.3)\n",
            "Collecting ir-datasets>=0.3.2 (from python-terrier)\n",
            "  Downloading ir_datasets-0.5.9-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting wget (from python-terrier)\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyjnius>=1.4.2 (from python-terrier)\n",
            "  Downloading pyjnius-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: deprecated in /usr/local/lib/python3.11/dist-packages (from python-terrier) (1.2.18)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from python-terrier) (1.13.1)\n",
            "Collecting ir-measures>=0.3.1 (from python-terrier)\n",
            "  Downloading ir_measures-0.3.7-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting pytrec-eval-terrier>=0.5.3 (from python-terrier)\n",
            "  Downloading pytrec_eval_terrier-0.5.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (777 bytes)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from python-terrier) (3.1.5)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (from python-terrier) (0.14.4)\n",
            "Collecting dill (from python-terrier)\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from python-terrier) (1.4.2)\n",
            "Collecting chest (from python-terrier)\n",
            "  Downloading chest-0.2.3.tar.gz (9.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting lz4 (from python-terrier)\n",
            "  Downloading lz4-4.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from ir-datasets>=0.3.2->python-terrier) (4.13.3)\n",
            "Collecting inscriptis>=2.2.0 (from ir-datasets>=0.3.2->python-terrier)\n",
            "  Downloading inscriptis-2.5.3-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: lxml>=4.5.2 in /usr/local/lib/python3.11/dist-packages (from ir-datasets>=0.3.2->python-terrier) (5.3.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ir-datasets>=0.3.2->python-terrier) (6.0.2)\n",
            "Collecting trec-car-tools>=2.5.4 (from ir-datasets>=0.3.2->python-terrier)\n",
            "  Downloading trec_car_tools-2.6-py3-none-any.whl.metadata (640 bytes)\n",
            "Collecting warc3-wet>=0.2.3 (from ir-datasets>=0.3.2->python-terrier)\n",
            "  Downloading warc3_wet-0.2.5-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting warc3-wet-clueweb09>=0.2.5 (from ir-datasets>=0.3.2->python-terrier)\n",
            "  Downloading warc3-wet-clueweb09-0.2.5.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting zlib-state>=0.1.3 (from ir-datasets>=0.3.2->python-terrier)\n",
            "  Downloading zlib_state-0.1.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting ijson>=3.1.3 (from ir-datasets>=0.3.2->python-terrier)\n",
            "  Downloading ijson-3.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Collecting unlzw3>=0.2.1 (from ir-datasets>=0.3.2->python-terrier)\n",
            "  Downloading unlzw3-0.2.3-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->python-terrier) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->python-terrier) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->python-terrier) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->python-terrier) (2025.1.31)\n",
            "Collecting heapdict (from chest->python-terrier)\n",
            "  Downloading HeapDict-1.0.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated->python-terrier) (1.17.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->python-terrier) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->python-terrier) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->python-terrier) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->python-terrier) (2025.1)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels->python-terrier) (1.0.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels->python-terrier) (24.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.4.1->ir-datasets>=0.3.2->python-terrier) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.4.1->ir-datasets>=0.3.2->python-terrier) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->python-terrier) (1.17.0)\n",
            "Collecting cbor>=1.0.0 (from trec-car-tools>=2.5.4->ir-datasets>=0.3.2->python-terrier)\n",
            "  Downloading cbor-1.0.0.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Downloading python_terrier-0.13.0-py3-none-any.whl (163 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.4/163.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ir_datasets-0.5.9-py3-none-any.whl (347 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.9/347.9 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ir_measures-0.3.7-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lz4-4.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyjnius-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytrec_eval_terrier-0.5.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.9/287.9 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ijson-3.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.2/119.2 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading inscriptis-2.5.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trec_car_tools-2.6-py3-none-any.whl (8.4 kB)\n",
            "Downloading unlzw3-0.2.3-py3-none-any.whl (6.7 kB)\n",
            "Downloading warc3_wet-0.2.5-py3-none-any.whl (18 kB)\n",
            "Downloading zlib_state-0.1.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
            "Downloading HeapDict-1.0.1-py3-none-any.whl (3.9 kB)\n",
            "Building wheels for collected packages: chest, wget, warc3-wet-clueweb09, cbor\n",
            "  Building wheel for chest (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for chest: filename=chest-0.2.3-py3-none-any.whl size=7611 sha256=f9c8549af3fca998e792d3d000545e453b4cf3a5ebfb38d99765f660e445da7e\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/57/13/28831e81239278141f874ee9b7d6d5490a1b1191c2d07a3e73\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=a91c4d08be446187129db769ce91536b5e278204f285163eb06deaab4506b2bc\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "  Building wheel for warc3-wet-clueweb09 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for warc3-wet-clueweb09: filename=warc3_wet_clueweb09-0.2.5-py3-none-any.whl size=18920 sha256=9ae6be600e70b4ea47f1be9a881da6a06f066ac1dfda8b27f6c4f00618710ccf\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/f9/dc/2dd16d3330e327236e4d407941975c42d5159d200cdb7922d8\n",
            "  Building wheel for cbor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cbor: filename=cbor-1.0.0-cp311-cp311-linux_x86_64.whl size=53927 sha256=ee4b3b656375262ea879ff0f240d4868fb3a6d8ecd10ca23b0a025a8d757084a\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/6b/45/0c34253b1af07d1d9dc524f6d44d74a6b191c43152e6aaf641\n",
            "Successfully built chest wget warc3-wet-clueweb09 cbor\n",
            "Installing collected packages: wget, warc3-wet-clueweb09, warc3-wet, pyjnius, ijson, heapdict, cbor, zlib-state, unlzw3, trec-car-tools, pytrec-eval-terrier, lz4, dill, chest, ir-measures, inscriptis, ir-datasets, python-terrier\n",
            "Successfully installed cbor-1.0.0 chest-0.2.3 dill-0.3.9 heapdict-1.0.1 ijson-3.3.0 inscriptis-2.5.3 ir-datasets-0.5.9 ir-measures-0.3.7 lz4-4.4.3 pyjnius-1.6.1 python-terrier-0.13.0 pytrec-eval-terrier-0.5.6 trec-car-tools-2.6 unlzw3-0.2.3 warc3-wet-0.2.5 warc3-wet-clueweb09-0.2.5 wget-3.2 zlib-state-0.1.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIzygfXzAILT"
      },
      "source": [
        "The next step is to initialize PyTerrier. This is performed using PyTerrier's init() method. The init() method is needed as PyTerrier must download Terrier's jar file and start the Java virtual machine. We prevent init() from being called more than once by checking started()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adAChFH6AN1C"
      },
      "source": [
        "import pyterrier as pt\n",
        "if not pt.started():\n",
        "  pt.init()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMSW5eI-TQGX"
      },
      "source": [
        "Another library that we need for this lab is Arabic-Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENifjmGeTf6Q"
      },
      "source": [
        "#install the Arabic stop words library\n",
        "!pip install Arabic-Stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnwlwDLJT48p"
      },
      "source": [
        "We will import all the python libraries needed for this lab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Os60lty5UD-s"
      },
      "source": [
        "#we need to import the following libraries.\n",
        "import pandas as pd\n",
        "#to display the full text on the notebook without truncation\n",
        "pd.set_option('display.max_colwidth', 150)\n",
        "import numpy as np\n",
        "import re\n",
        "from snowballstemmer import stemmer\n",
        "from tqdm import tqdm\n",
        "import arabicstopwords.arabicstopwords as stp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkxBHwFE8LH6"
      },
      "source": [
        "We will prepare our helper functions for removing stop words, normalize, and stemming which we will use to process our queries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KWReIAF8Rxz"
      },
      "source": [
        "#removing Stop Words function\n",
        "def remove_stopWords(sentence):\n",
        "    terms=[]\n",
        "    stopWords= set(stp.stopwords_list())\n",
        "    for term in sentence.split() :\n",
        "        if term not in stopWords :\n",
        "           terms.append(term)\n",
        "    return \" \".join(terms)\n",
        "\n",
        "#a function to normalize the tweets\n",
        "def normalize(text):\n",
        "    text = re.sub(\"[إأٱآا]\", \"ا\", text)\n",
        "    text = re.sub(\"ى\", \"ي\", text)\n",
        "    text = re.sub(\"ؤ\", \"ء\", text)\n",
        "    text = re.sub(\"ئ\", \"ء\", text)\n",
        "    text = re.sub(\"ة\", \"ه\", text)\n",
        "    return(text)\n",
        "\n",
        "#define the stemming function\n",
        "ar_stemmer = stemmer(\"arabic\")\n",
        "def stem(sentence):\n",
        "    return \" \".join([ar_stemmer.stemWord(i) for i in sentence.split()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQ170aUr7b2D"
      },
      "source": [
        "We will use our indexed **EveTAR** dataset. The index is uploaded in our Github repository so we will access it as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkHkRSGz7sfF"
      },
      "source": [
        "# %rm -rf IR-in-Arabic\n",
        "# %rm -rf evetarIndex\n",
        "!git clone https://github.com/telsayed/IR-in-Arabic.git\n",
        "!unzip IR-in-Arabic/Summer2021/data/EveTAR/evetarIndex.zip -d evetarIndex\n",
        "!ls evetarIndex"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orkznRg8-VXx"
      },
      "source": [
        "Next, we will load our index. We jus need the data.properties file to load our index."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuqjM544-ZKx"
      },
      "source": [
        "#we will load the index\n",
        "index_ref = pt.IndexRef.of(\"./evetarIndex/data.properties\")\n",
        "index = pt.IndexFactory.of(index_ref)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgIpOhpCL_QO"
      },
      "source": [
        "### **Vector space model retrieval**\n",
        "We will use BatchRetrieve Pyterrier class for retrieval and TF-IDF as the weighting model. You can check the weighting models supported by PyTerrier [here](http://terrier.org/docs/current/javadoc/org/terrier/matching/models/package-summary.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-N8p6NpMOha"
      },
      "source": [
        "#set up our retieval model by specifing TF_IDF as wmodel and limiting the number of retrieved results for each query top 10 documents\n",
        "tfidf_retr = pt.BatchRetrieve(index, controls = {\"wmodel\": \"TF_IDF\"},num_results=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7V5-Ih4M36J"
      },
      "source": [
        "You can query using a simple string. **Note:** you need to preprocess the query using the same processing steps you performed before indexing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O371L3r0NBw8"
      },
      "source": [
        "#we need to process the query also as we did for documents\n",
        "def preprocess(sentence):\n",
        "  # apply preprocessing steps on the given sentence\n",
        "  # students ToDo .....\n",
        "  # here you should write your code\n",
        "  return sentence\n",
        "\n",
        "query=\"العربية\"\n",
        "query = preprocess(query)\n",
        "#we will call the search function using our retrieval model we set up above\n",
        "results=tfidf_retr.search(query)\n",
        "results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRBeLsRvC1Dv"
      },
      "source": [
        "Let's check the tweets retrieved by getting the tweets text from our collection."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-bw0opJC77n"
      },
      "source": [
        "dataset_links=[\"https://raw.githubusercontent.com/telsayed/IR-in-Arabic/master/Summer2021/data/EveTAR/tweets/evetar-q-01.txt\",\n",
        "               \"https://raw.githubusercontent.com/telsayed/IR-in-Arabic/master/Summer2021/data/EveTAR/tweets/evetar-q-02.txt\",\n",
        "               \"https://raw.githubusercontent.com/telsayed/IR-in-Arabic/master/Summer2021/data/EveTAR/tweets/evetar-q-03.txt\",\n",
        "               \"https://raw.githubusercontent.com/telsayed/IR-in-Arabic/master/Summer2021/data/EveTAR/tweets/evetar-q-04.txt\",\n",
        "               \"https://raw.githubusercontent.com/telsayed/IR-in-Arabic/master/Summer2021/data/EveTAR/tweets/evetar-q-05.txt\",\n",
        "               \"https://raw.githubusercontent.com/telsayed/IR-in-Arabic/master/Summer2021/data/EveTAR/tweets/evetar-q-06.txt\",\n",
        "               \"https://raw.githubusercontent.com/telsayed/IR-in-Arabic/master/Summer2021/data/EveTAR/tweets/evetar-q-07.txt\",\n",
        "               \"https://raw.githubusercontent.com/telsayed/IR-in-Arabic/master/Summer2021/data/EveTAR/tweets/evetar-q-08.txt\",\n",
        "               \"https://raw.githubusercontent.com/telsayed/IR-in-Arabic/master/Summer2021/data/EveTAR/tweets/evetar-q-09.txt\",\n",
        "               \"https://raw.githubusercontent.com/telsayed/IR-in-Arabic/master/Summer2021/data/EveTAR/tweets/evetar-q-10.txt\"]\n",
        "\n",
        "full_data=pd.DataFrame()\n",
        "for i in tqdm(range(len(dataset_links))):\n",
        "    tweets=pd.read_csv(dataset_links[i], sep='\\t')\n",
        "    full_data=pd.concat([full_data,tweets],ignore_index=True)\n",
        "full_data.reset_index(inplace=True,drop=True)\n",
        "#the docno will be our tweetID\n",
        "full_data[\"docno\"]=full_data[\"tweetID\"].astype(str)\n",
        "#select tweet text for the tweets retrieved only\n",
        "full_data[full_data[\"docno\"].isin(results[\"docno\"].tolist())]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGrQzoKfFmt-"
      },
      "source": [
        "Let's try another query."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rl2OFswZCQ9u"
      },
      "source": [
        "#we need to process the term also as we did for documents\n",
        "query=\"أمريكا دولار\"\n",
        "#preprocess\n",
        "query = preprocess(query)\n",
        "#we will call the search function using our retrieval model we set up above\n",
        "results=tfidf_retr.search(query)\n",
        "results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oghHX0_pzDSk"
      },
      "source": [
        "Let's check our results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-Yue4KyDzlv"
      },
      "source": [
        "# retrieve the tweets text for the retrieved tweets just to check our results\n",
        "full_data[full_data[\"docno\"].isin(results[\"docno\"].tolist())]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIL0VhkxXi6z"
      },
      "source": [
        "We will load queries (topics titles) that are already defined and released with EveTAR dataset and process using the same processing steps we did when we indexed EveTAR."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAjn8zFGW4x0"
      },
      "source": [
        "#read the topics file from Github and use the titles as queries\n",
        "topics=pd.read_csv(\"https://raw.githubusercontent.com/telsayed/IR-in-Arabic/master/Summer2021/data/EveTAR/topics.txt\", sep='\\t',names=['data'])\n",
        "queries=[]\n",
        "qid=[]\n",
        "#we will get the queries and their ids from the topics file\n",
        "for i in range(len(topics)):\n",
        "    splitted=topics[\"data\"][i:i+1][i].split(\" \")\n",
        "    if splitted[0]==\"<title>\":\n",
        "       queries.append(' '.join(splitted[1:]))\n",
        "    if splitted[0]==\"<num>\":\n",
        "       qid.append(splitted[2])\n",
        "\n",
        "queriesDF=pd.DataFrame()\n",
        "queriesDF[\"qid\"]=qid\n",
        "queriesDF[\"raw_query\"]=queries\n",
        "#remove the stopwords from queries, do normalization, and apply stemming\n",
        "queriesDF[\"query\"]=queriesDF[\"raw_query\"].apply(preprocess)\n",
        "\n",
        "queriesDF"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9P61FAxNehR"
      },
      "source": [
        "We can retrieve the relevant documents to a set of queries using the **transform** function. We will use the set of queries we prepared earlier. The input should be a dataframe containing the **qid** and **query**. The function will return the same dataframe but with an extra 4 columns **docid**, **docno**, **rank**, and **score**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5He7zRGNpYP"
      },
      "source": [
        "#the queries dataframe should have qid and query columns\n",
        "tfidf_res=tfidf_retr.transform(queriesDF)\n",
        "tfidf_res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Su6rpeNrOJH7"
      },
      "source": [
        "### **BM25**\n",
        "\n",
        "We will initialize our BM25 retrieval model by using the BatchRetrieve class and setting the weighting model to BM25."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkSaFH67OvFf"
      },
      "source": [
        "#specify BM25 as wmodel\n",
        "bm25_retr = pt.BatchRetrieve(index, controls = {\"wmodel\": \"BM25\"},num_results=10)\n",
        "#the queries dataframe should have qid and query columns\n",
        "bm25_res=bm25_retr.transform(queriesDF)\n",
        "bm25_res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdUzSE0mPLTP"
      },
      "source": [
        "### **Evaluating our results**\n",
        "To evaluate the results we need qrels (relevance judgements). The qrels should be in [TREC format](https://trec.nist.gov/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k28ejDvJRbx5"
      },
      "source": [
        "qrels=pd.read_csv(\"https://raw.githubusercontent.com/telsayed/IR-in-Arabic/master/Summer2021/data/EveTAR/qrels.txt\", sep='\\t',names=['qid','Q0','docno','label'])\n",
        "qrels['docno']=qrels['docno'].astype(str)\n",
        "# qrels are in TREC format\n",
        "qrels = qrels[qrels[\"docno\"].isin(full_data[\"docno\"].tolist())] # to choose qrels for the chosen 50k documents\n",
        "qrels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ozsa0BVoRo4t"
      },
      "source": [
        "Let's see an example of a dataset with graded relevance judgement."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXnbTiNGIW45"
      },
      "source": [
        "#check the following dataset available by PyTerrier. The relevance is graded\n",
        "pt.get_dataset(\"trec-robust-2004\").get_qrels()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVvjj4EDI6jR"
      },
      "source": [
        "#check the unique labels\n",
        "pt.get_dataset(\"trec-robust-2004\").get_qrels()['label'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfBwU7oXyPLB"
      },
      "source": [
        "To evaluate our results we will use Pyterrier Utils.evaluate function. This function take the results and the qrels dataframe containing three columns which are **qid, docno, label.**\n",
        "\n",
        "You can add the following parameters:\n",
        "\n",
        "\n",
        "*   **metrics**: default = [\"map\", ndcg\"], select the evaluation metrics\n",
        "\n",
        "*   **perquery**: default = False, select whether to show the mean of the metrics or the metrics for each queryList item\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUpw9cssyoLq"
      },
      "source": [
        "# Here, we are evaluating TF_IDF retrieval model\n",
        "eval = pt.Utils.evaluate(tfidf_res,qrels[['qid','docno','label']],metrics=[\"map\",\"recall\",\"P\"])\n",
        "eval"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QdMp3pb0uK2"
      },
      "source": [
        "# Here, we are evaluating BM25 retrieval model\n",
        "eval = pt.Utils.evaluate(bm25_res,qrels[['qid','docno','label']],metrics=[\"map\",\"recall\",\"P\"])\n",
        "eval"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dfj5Swv2URm"
      },
      "source": [
        "# Here, we are evaluating bm25 retreival model BUT with activating perquery flag\n",
        "eval = pt.Utils.evaluate(bm25_res,qrels[['qid','docno','label']],metrics=[\"map\",\"recall\",\"P\"],perquery=True)\n",
        "eval"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbEocrBp7sTm"
      },
      "source": [
        "### **Exercise 1**\n",
        "Select three queries from our 50 queries and retrieve the top 25 relevant tweets for those queries using both the TF-IDF and the BM25 retrieval models. Evaluate your results in terms of precision only."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DFMPfu18nP3"
      },
      "source": [
        "# write your solution here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6590-CeSgSOr"
      },
      "source": [
        "### **Exercise 2**\n",
        "Given the following queries:\n",
        "\n",
        "['E14' 'E48' 'E36' 'E58' 'E19' 'E63' 'E30' 'E27' 'E39' 'E21']\n",
        "\n",
        "1. Retreive the top 1000 relevant documents using BM25.\n",
        "2. Retrieve the text for both queries and documents and make them into one dataframe.\n",
        "3. Save the resulted dataframe into a text file.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgRvwa2dUdBb"
      },
      "source": [
        "selected_queries = ['E14','E48', 'E36', 'E58', 'E19', 'E63', 'E30', 'E27', 'E39', 'E21']\n",
        "# write your solution here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71_fMCB2FXIG"
      },
      "source": [
        "### **References**\n",
        "\n",
        "\n",
        "* [PyTerrier  retrieval and evaluation notebook](https://github.com/terrier-org/pyterrier/blob/master/examples/notebooks/retrieval_and_evaluation.ipynb).\n",
        "*   [PyTerrier documentation.](https://pyterrier.readthedocs.io/_/downloads/en/latest/pdf/)\n",
        "\n"
      ]
    }
  ]
}